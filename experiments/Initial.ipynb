{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09f87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from MINE.mi import MineClassif, MineOpt\n",
    "from MINE.augmentation import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models as keras_models\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "plt.rcParams['figure.figsize'] = 20, 15\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "894ebb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_model(input_x_shape, input_z_shape, activation):\n",
    "    inp_x = Input((input_x_shape, ))\n",
    "    inp_z = Input((input_z_shape, ))\n",
    "\n",
    "    x = layers.Concatenate()([inp_x, inp_z])\n",
    "    x = layers.Dense(64, activation='tanh')(x)\n",
    "    x = layers.Dense(1, activation=activation)(x)\n",
    "    \n",
    "    model = Model(inputs=[inp_x, inp_z], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0397af64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uni(n, d):\n",
    "    tmp = np.random.choice(range(d), n)\n",
    "    tmp2 = np.zeros((tmp.size, tmp.max() + 1))\n",
    "    tmp2[np.arange(tmp.size), tmp] = 1\n",
    "    return tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be5d7fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_opt(dataset, approx, L, lam, C, x_ind, y_ind):\n",
    "    model = construct_model(len(x_ind), len(y_ind))\n",
    "    mine = MineOpt(model, approximation=approx, L=L, lam=lam, C=C)\n",
    "    mine.compile(optimizer='adam')\n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=20, monitor='mi', mode='max')\n",
    "    history = mine.fit([dataset[:, x_ind], dataset[:, y_ind]], None, batch_size=256, epochs=1000, callbacks=[es], verbose=0)\n",
    "    return mine\n",
    "\n",
    "def fit_model_classif(dataset, x_ind, y_ind):\n",
    "    model = construct_model(len(x_ind), len(y_ind))\n",
    "    mine = Mine(model)\n",
    "    mine.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    es = tf.keras.callbacks.EarlyStopping(patience=20, monitor='loss', mode='min')\n",
    "    history = mine.fit([dataset[:, x_ind], dataset[:, y_ind]], None, batch_size=256, epochs=1000, callbacks=[es], verbose=0)\n",
    "    return mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa97a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(77)\n",
    "\n",
    "uni = {100: {}, 1000: {}, 10_000: {}}\n",
    "uni[100]['orig'] = [create_uni(100, 16) for i in range(30)]\n",
    "uni[1000]['orig'] = [create_uni(1000, 16) for i in range(30)]\n",
    "uni[10_000]['orig'] = [create_uni(10_000, 16) for i in range(30)]\n",
    "\n",
    "\n",
    "norm_not_corr = {100: {}, 1000: {}, 10_000: {}}\n",
    "mean = np.array([0, 1])\n",
    "cov = np.array([[1, 0], [0, 2]])\n",
    "norm_not_corr[10_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=10_000) for i in range(30)]\n",
    "norm_not_corr[1_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=1_000) for i in range(30)]\n",
    "norm_not_corr[100]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=100) for i in range(30)]\n",
    "\n",
    "norm_corr = {}\n",
    "mean = np.array([0, 1])\n",
    "cov = np.array([[1, 0.75], [0.75, 2]])\n",
    "norm_corr = {100: {}, 1000: {}, 10_000: {}}\n",
    "norm_corr[10_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=10_000) for i in range(30)]\n",
    "norm_corr[1_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=1_000) for i in range(30)]\n",
    "norm_corr[100]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=100) for i in range(30)]\n",
    "\n",
    "norm_hd = {}\n",
    "mean = np.array([-4, -3, -2, -1, 0, 1, 2, 3, 4])\n",
    "A = np.random.uniform(-1, 1, 81).reshape(9, 9)\n",
    "cov = np.matmul(A, A.T)\n",
    "norm_hd = {100: {}, 1000: {}, 10_000: {}}\n",
    "norm_hd[10_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=10_000) for i in range(30)]\n",
    "norm_hd[1_000]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=1_000) for i in range(30)]\n",
    "norm_hd[100]['orig'] = [np.random.multivariate_normal(mean=mean, cov=cov, size=100) for i in range(30)]\n",
    "\n",
    "datasets = {'uni': uni, 'norm_not_corr': norm_not_corr, 'norm_corr': norm_corr, 'norm_hd': norm_hd}\n",
    "\n",
    "aug = Augmentation()\n",
    "\n",
    "for dataset_type_name, dataset_type in datasets.items():\n",
    "    for dataset_size_name, dataset_size in dataset_type.items():\n",
    "        dataset_size['aug'] = [aug.transform(dataset_size['orig'][i], n=10, m=1) for i in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7b7a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "for dataset_type_name, dataset_type in tqdm(datasets.items()):\n",
    "    models[dataset_type_name] = {}\n",
    "    for dataset_size_name, dataset_size in tqdm(dataset_type.items()):\n",
    "        models[dataset_type_name][dataset_size_name] = {'orig':\n",
    "                                     {'DV': {'l0': [],\n",
    "                                             'l0.1': []\n",
    "                                            },\n",
    "                                      'FD': {'l0': [],\n",
    "                                             'l0.1': []\n",
    "                                            },\n",
    "                                     },\n",
    "                                     'aug': {'DV': {'l0': [],\n",
    "                                             'l0.1': []\n",
    "                                            },\n",
    "                                              'FD': {'l0': [],\n",
    "                                                     'l0.1': []\n",
    "                                                    }\n",
    "                                     }\n",
    "                                    }\n",
    "        for i in range(30):\n",
    "            mine = fit_model(dataset_size['orig'][i], 'Donsker_Varadhan', L=None)\n",
    "            models[dataset_type_name][dataset_size_name]['orig']['DV']['l0'].append(mine)\n",
    "            \n",
    "            mine = fit_model(dataset_size['orig'], 'Donsker_Varadhan', L=2, lam=0.1, C=0)\n",
    "            models[dataset_type_name][dataset_size_name]['orig']['DV']['l0.1'].append(mine)\n",
    "            \n",
    "            mine = fit_model(dataset_size['orig'], 'f_divergence', L=None)\n",
    "            models[dataset_type_name][dataset_size_name]['orig']['FD']['l0'].append(mine)\n",
    "            \n",
    "            mine = fit_model(dataset_size['orig'], 'f_divergence', L=2, lam=0.1, C=1)\n",
    "            models[dataset_type_name][dataset_size_name]['orig']['FD']['l0.1'].append(mine)\n",
    "\n",
    "            models[dataset_type_name][dataset_size_name]['aug']['DV']['l0'].append([])\n",
    "            models[dataset_type_name][dataset_size_name]['aug']['DV']['l0.1'].append([])\n",
    "            models[dataset_type_name][dataset_size_name]['aug']['FD']['l0'].append([])\n",
    "            models[dataset_type_name][dataset_size_name]['aug']['FD']['l0.1'].append([])\n",
    "            for j in range(10):\n",
    "                mine = fit_model(dataset_size['aug'][i][j], 'Donsker_Varadhan', None)\n",
    "                models[dataset_type_name][dataset_size_name]['aug']['DV']['l0'][-1].append(mine)\n",
    "                \n",
    "                mine = fit_model(dataset_size['aug'][i][j], 'Donsker_Varadhan', L=2, lam=0.1, C=0)\n",
    "                models[dataset_type_name][dataset_size_name]['aug']['DV']['l0.1'][-1].append(mine)\n",
    "                \n",
    "                mine = fit_model(dataset_size['aug'][i][j], 'f_divergence', L=None)\n",
    "                models[dataset_type_name][dataset_size_name]['aug']['FD']['l0'][-1].append(mine)\n",
    "                \n",
    "                mine = fit_model(dataset_size['aug'][i][j], 'f_divergence', L=2, lam=0.1, C=1)\n",
    "                models[dataset_type_name][dataset_size_name]['aug']['FD']['l0.1'][-1].append(mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100505c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_experiments(n, seed):\n",
    "    seed = int(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    datasets = prepare_datasets(n)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        result[dataset_name] = {n: {'orig':\n",
    "                                     {'DV': {'l0': {seed: None},\n",
    "                                             'l0.1': {seed: None}\n",
    "                                            },\n",
    "                                      'FD': {'l0': {seed: None},\n",
    "                                             'l0.1': {seed: None}\n",
    "                                            },\n",
    "                                     },\n",
    "                                     'aug': {'DV': {'l0': {seed: []},\n",
    "                                             'l0.1': {seed: []}\n",
    "                                            },\n",
    "                                              'FD': {'l0': {seed: []},\n",
    "                                                     'l0.1': {seed: []}\n",
    "                                                    }\n",
    "                                     }\n",
    "                                    }\n",
    "        print(\":)\")\n",
    "        if 'aug' not in dataset_name:\n",
    "            m = fit_model(dataset, 'Donsker_Varadhan', L=None)\n",
    "            result[dataset_name][n]['orig']['DV']['l0'][seed] = m\n",
    "\n",
    "            m = fit_model(dataset, 'Donsker_Varadhan', L=2, lam=0.1, C=0)\n",
    "            result[dataset_name][n]['orig']['DV']['l0.1'][seed] = m\n",
    "\n",
    "            m = fit_model(dataset, 'f_divergence', L=None)\n",
    "            result[dataset_name][n]['orig']['f_divergence']['l0'][seed] = m\n",
    "\n",
    "            m = fit_model(dataset, 'f_divergence', L=2, lam=0.1, C=1)\n",
    "            result[dataset_name][n]['orig']['f_divergence']['l0.1'][seed] = m\n",
    "        else:\n",
    "            for i in range(10):\n",
    "                m = fit_model(dataset, 'Donsker_Varadhan', L=None)\n",
    "                result[dataset_name][n]['aug']['DV']['l0'][seed].append(m)\n",
    "\n",
    "                m = fit_model(dataset, 'Donsker_Varadhan', L=2, lam=0.1, C=0)\n",
    "                result[dataset_name][n]['aug']['DV']['l0.1'][seed].append(m)\n",
    "\n",
    "                m = fit_model(dataset, 'f_divergence', L=None)\n",
    "                result[dataset_name][n]['aug']['f_divergence']['l0'][seed].append(m)\n",
    "\n",
    "                m = fit_model(dataset, 'f_divergence', L=2, lam=0.1, C=1)\n",
    "                result[dataset_name][n]['aug']['f_divergence']['l0.1'][seed].append(m)\n",
    "\n",
    "    dt = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    with open(f'results/{n}_{seed}_{dt}.pkl', 'wb') as fd:\n",
    "        pickle.dump(results, fd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
